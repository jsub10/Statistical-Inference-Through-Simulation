{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coinToss(bias, numTosses): \n",
    "    # bias is always for the first element of vals\n",
    "    vals = [\"H\", \"T\"]\n",
    "    outcomes = list(np.random.choice(vals, numTosses, p=(bias,1 - bias)))\n",
    "    #print outcomes\n",
    "    # count the number of heads\n",
    "    rawCount = outcomes.count(\"H\")\n",
    "    # Sometimes there can be no H at all; handle this when it happens\n",
    "    try:\n",
    "        normCount = rawCount/numTosses\n",
    "    except ZeroDivisionError:\n",
    "        normCount = 0.\n",
    "    \n",
    "    return rawCount, normCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probCoinTossOutcome(bias, numTosses, numEvents, slack = 0):\n",
    "    \n",
    "    # numEvents is the number of times we get heads when the coin is tossed numTosses times\n",
    "    # slack is the range around the number of events -- when numTosses and numEvents are large\n",
    "    # typically slack is a function of numTosses; it can range from 1/10 th of numTosses to 1/100 th of numTosses\n",
    "    \n",
    "    # Generate the outcomes\n",
    "    # Keep numTrials sufficiently large but not too large - it's computationally expensive\n",
    "    # 10,000 is more than sufficient; 1,000 is a good practical limit\n",
    "    numTrials = 5000\n",
    "    outcomes = [coinToss(bias, numTosses) for i in range(numTrials)]\n",
    "    \n",
    "    # Count the number of times we get numEvents heads\n",
    "    # headsList = [outcome[:1] for outcome in outcomes]\n",
    "    headsList = [x for (x,y) in outcomes]\n",
    "    # headsCount = [h[0] for h in headsList].count(numEvents)\n",
    "    # eventsFired is written to accommodate some slack when the numTosses and hence, the possible numEvents grow large\n",
    "    eventsFired = [heads for heads in headsList if (heads >= numEvents - slack) and (heads <= numEvents + slack)]\n",
    "    numEventsFired = len(eventsFired)\n",
    "    #probOutcome = headsCount/float(numTrials)\n",
    "    probOutcome = numEventsFired/float(numTrials)\n",
    "    \n",
    "    return [bias, numTosses, numEvents, slack, probOutcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize a list of values so that they always add up to 1\n",
    "def normalize(valList):\n",
    "    # valList is a list of values, e.g., [0.3, ..., 0.02]\n",
    "    # valList can be any length\n",
    "    sumVals = sum(valList)\n",
    "    normList = []\n",
    "    for val in valList:\n",
    "        normVal = val/sumVals\n",
    "        normList.append(normVal)\n",
    "        \n",
    "    return normList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coinTossPValue(bias, numTosses, numEvents, slack, tailed=\"two-tailed\"):\n",
    "    \n",
    "    # bias is the hypotheses that the coin has that given bias\n",
    "    # numTosses is the number of times the coin is tossed\n",
    "    # numEvents is the number of times we get heads when the coin is tosses numTosses times\n",
    "    #  slack accounts for a range of values around numEvents rather than the exact value of numEvents\n",
    "    #  slack is useful when the number of tosses is large and hence the possible numEvents is a large set\n",
    "    #  In such a case, slack prevents the probability of numEvents given numTosses from always being \n",
    "    #  vanishingly close to zero\n",
    "    # tailed can be \"two-tailed\" (default), \"left-tailed\" or \"right-tailed\"\n",
    "    \n",
    "    # Find the probabilities for all the possible outcomes\n",
    "    probsAllOutcomes = [probCoinTossOutcome(bias, numTosses, i, slack) for i in range(numTosses + 1)]\n",
    "    \n",
    "    # Just get the probabilities \n",
    "    #probsList = [p[1:2][0] for p in probsAllOutcomes]\n",
    "    probsList = [probs[4] for probs in probsAllOutcomes]\n",
    "    \n",
    "    # Normalize the probs given that the slack will produce values that will exceed 1 when added together\n",
    "    normalizedProbs = normalize(probsList)\n",
    "    \n",
    "    # Probability of the required outcome -- i.e., numEvents\n",
    "    probRequired = normalizedProbs[numEvents]\n",
    "    \n",
    "    # Identify and sum all the probabilities in normalizedProbs that are less than or equal to probRequired\n",
    "    # including probRequired.\n",
    "    # By default this is for a two-tailed sum.\n",
    "    pList = []\n",
    "    for p in normalizedProbs:\n",
    "        if p <= probRequired:\n",
    "            pList.append(p)\n",
    "    \n",
    "    # Left tail list of probabilities\n",
    "    pListLeftTailed = []\n",
    "    for index, prob in enumerate(normalizedProbs):\n",
    "        if (prob <= probRequired) and (index <= numEvents):\n",
    "            pListLeftTailed.append(prob)\n",
    "            \n",
    "    # Right tail list of probabilities\n",
    "    pListRightTailed = []\n",
    "    for index, prob in enumerate(normalizedProbs):\n",
    "        if (prob <= probRequired) and (index >= numEvents):\n",
    "            pListRightTailed.append(prob)\n",
    "    \n",
    "    # The two-tailed p-value is the sum of all the probabilities in pList\n",
    "    pValue = sum(pList)\n",
    "    \n",
    "    # Left tailed p-value is the sum of all the probabilities in the pListLeftTailed\n",
    "    pValueLeftTailed = sum(pListLeftTailed)\n",
    "    \n",
    "    # Right tailed p-value is the sum of all the probabilities in the pListRightTailed\n",
    "    pValueRightTailed = sum(pListRightTailed)\n",
    "    \n",
    "    # Set the p-value displayed based on the input value of the tailed variable\n",
    "    if tailed == \"two-tailed\":\n",
    "        pValueDisplay = pValue\n",
    "    elif tailed == \"left-tailed\":\n",
    "        pValueDisplay = pValueLeftTailed\n",
    "    elif tailed == \"right-tailed\":\n",
    "        pValueDisplay = pValueRightTailed\n",
    "    else:\n",
    "        pValueDisplay = pValue\n",
    "    \n",
    "    #return probsList, probRequired, pList, pValue\n",
    "    return [bias, numTosses, numEvents, pValueDisplay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hypoDiagnosticTest(numTosses, numEvents, alpha, slack = 0, tailed = \"two-tailed\"):\n",
    "    # For a given bit of evidence, calculates the p-values for each possible hypothesis that \n",
    "    # could have generated that evidence. Also reveals if the hypothesis is accepted or rejected.\n",
    "    \n",
    "    # numTosses and numEvents together constitute the evidence\n",
    "    # alpha is the significance level\n",
    "    # slack is for discrete probability distributions where the x-axis values are large\n",
    "    # slack is a way of treating probability mass functions with large values of numTosses \n",
    "    # as continuous functions (i.e., PDFs)\n",
    "    \n",
    "    # Check input integrity\n",
    "    if (numEvents > numTosses) or (numEvents < 0):\n",
    "        return \"Please ensure that numTosses is a positive integer less than or equal to numTosses\"\n",
    "    \n",
    "    if (alpha < 0) or (alpha > 1):\n",
    "        return \"Please enter a value for alpha between 0 and 1\"\n",
    "    \n",
    "    if (slack < 0) or (slack >= numTosses):\n",
    "        return \"Please enter a reasonable value for the slack\"\n",
    "    \n",
    "    if (tailed != \"two-tailed\") and (tailed != \"left-tailed\") and (tailed != \"right-tailed\"):\n",
    "        return \"Please set the tailed value to one of the following: 'two-tailed', 'left-tailed' or 'right-tailed'\"\n",
    "    \n",
    "    # ASSUME that possible biases of the coin are 0, 0.1, ..., 1.0\n",
    "    biases = list(np.arange(0,1.1,0.1))\n",
    "    \n",
    "    # Get the p-value for each bias hypothesis\n",
    "    pValueForEachBias = [coinTossPValue(bias, numTosses, numEvents, slack, tailed) for bias in biases]\n",
    "    # pValueForEachBias returns a list of lists containing [bias, numTosses, numEvents, p-value] for each bias value\n",
    "    \n",
    "    result = []\n",
    "    for pVal in pValueForEachBias:\n",
    "        if pVal[3] <= alpha:\n",
    "            pVal.append(\"Rejected\")\n",
    "            result.append(pVal)\n",
    "        else:\n",
    "            pVal.append(\"Accepted\")\n",
    "            result.append(pVal)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evidenceDiagnosticTest(bias, numTosses, alpha, slack = 0, tailed = \"two-tailed\"):\n",
    "    # For a given hypothesis of the bias value, calculates the p-values for each possible bit of evidence that \n",
    "    # could be seen. Also reveals if the evidence is accepted or rejected.\n",
    "    \n",
    "    # numTosses and numEvents together constitute the evidence\n",
    "    # numEvents is not specified explicitly because it ranges from 0 to numTosses -- \n",
    "    # i.e., every possible outcome of number of heads in numTosses\n",
    "    \n",
    "    # alpha is the significance level\n",
    "    # slack is for discrete probability distributions where the x-axis values are large\n",
    "    # slack is a way of treating probability mass functions with large values of numTosses \n",
    "    # as continuous functions (i.e., PDFs)\n",
    "    \n",
    "    # Check input integrity\n",
    "    if (bias > 1) or (bias < 0):\n",
    "        return \"Please ensure that the hypoValue is a Real number between 0 and 1\"\n",
    "    \n",
    "    if (alpha < 0) or (alpha > 1):\n",
    "        return \"Please enter a value for alpha between 0 and 1\"\n",
    "    \n",
    "    if (slack < 0) or (slack >= numTosses):\n",
    "        return \"Please enter a reasonable value for the slack\"\n",
    "    \n",
    "    if (tailed != \"two-tailed\") and (tailed != \"left-tailed\") and (tailed != \"right-tailed\"):\n",
    "        return \"Please set the tailed value to one of the following: 'two-tailed', 'left-tailed' or 'right-tailed'\"\n",
    "    \n",
    "    # Generate all possible events\n",
    "    events = range(numTosses + 1)\n",
    "    \n",
    "    # Get the p-value for each bias hypothesis\n",
    "    pValueForEachEvent = [coinTossPValue(bias, numTosses, event, slack, tailed) for event in events]\n",
    "    # pValueForEachEvent returns a list of lists containing [bias, numTosses, numEvents, p-value] for each event value\n",
    "    \n",
    "    result = []\n",
    "    for eVal in pValueForEachEvent:\n",
    "        if eVal[3] <= alpha:\n",
    "            eVal.append(\"Rejected\")\n",
    "            result.append(eVal)\n",
    "        else:\n",
    "            eVal.append(\"Accepted\")\n",
    "            result.append(eVal)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOT USED\n",
    "# A function that perturbs a value\n",
    "# For a given set of possibilities, generate a set of probabilities \n",
    "def perturb(val, min, max, midPoint):\n",
    "    # val is the value that is being perturbated\n",
    "    # min is the minimum amount of perturbation\n",
    "    # max is the maximum amount of perturbation\n",
    "    # midPoint is the mid point between min and max. It can be set symmetrically\n",
    "    # or asymmetrically.\n",
    "    \n",
    "    # Check that midPoint is between min and max\n",
    "    if (midPoint < min) or (midPoint > max):\n",
    "        return \"Please choose a midPoint between min and max\"\n",
    "        \n",
    "    \n",
    "    pertVal = val + np.random.triangular(min,midPoint,max)\n",
    "    \n",
    "    return pertVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a random list of reals of a given length that add up to 1\n",
    "def discreteRandomDist(possibleOutcomes):\n",
    "    # possibleOutcomes are all the discrete events that are possible\n",
    "    # e.g., range(11) or [\"a\",\"b\",\"c\"]\n",
    "    \n",
    "    # generate reals between 0 and 1 (number of reals = length(possibleOutcomes))\n",
    "    probs = np.random.random_sample(len(possibleOutcomes))\n",
    "    \n",
    "    # normalize the probabilities to sum to 1\n",
    "    normalizedProbs = normalize(probs)\n",
    "   \n",
    "    return zip(possibleOutcomes, normalizedProbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.093566419425087546),\n",
       " (1, 0.087056770276490045),\n",
       " (2, 0.02358088158193759),\n",
       " (3, 0.03700801839715348),\n",
       " (4, 0.12117298601488767),\n",
       " (5, 0.15853615466541648),\n",
       " (6, 0.11379411706656661),\n",
       " (7, 0.069036280721851181),\n",
       " (8, 0.14455597570060991),\n",
       " (9, 0.028135937145045656),\n",
       " (10, 0.12355645900495391)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discreteRandomDist(range(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function that calculates the probability of a hypothesis given some evidence.\n",
    "# The hypothesis is in the form of a bias value for a coin\n",
    "# The priors are randomly generated\n",
    "# The evidence is in the form of the number of heads observed when the coin is tosses N times.\n",
    "# WORKS ONLY FOR DISCRETE OUTCOME STATES BETWEEN 0 and 1 IN INCREMENTS OF 0.1\n",
    "\n",
    "def bayes(bias, numTosses, numEvents, slack = 0):\n",
    "    \n",
    "    # generate a random initial distribution for all possible biases of the coin\n",
    "    # restricting the allowed biases to the Reals 0, 0.1, 0.2, ..., 0.9, 1.\n",
    "    # priorDist is the prior distribution over the possible bias values for the coin.\n",
    "    priorDist = discreteRandomDist(np.arange(0,1.1,0.1))\n",
    "    # just get the values\n",
    "    priorDistVals = [y for (x,y) in priorDist]\n",
    "    \n",
    "    # calculate the probability of the evidence for each possible bias value of the coin\n",
    "    probEvidenceForEachBias = [probCoinTossOutcome(i,numTosses,numEvents, slack) for i in np.arange(0,1.1,0.1)]\n",
    "    # just get the values and normalize them in case slack is > 0\n",
    "    probEvidenceForEachBiasVals = normalize([probEvidence[4] for probEvidence in probEvidenceForEachBias])\n",
    "    \n",
    "    # Probability of the evidence per se - i.e., the Bayesian normalization factor\n",
    "    pEvidence = np.sum(np.multiply(priorDistVals, probEvidenceForEachBiasVals))\n",
    "    \n",
    "    # From the priorDistVals, find the prior for the particular bias\n",
    "    # CAUTION: ONLY WORKS FOR DISCRETE COIN BIASES FROM 0 TO 1 in intervals of 0.1\n",
    "    biasPrior = priorDistVals[int(bias * 10)]\n",
    "    \n",
    "    # From the probEvidenceForAllHyposVals, find the probEvidence for the particular bias\n",
    "    # CAUTION: ONLY WORKS FOR DISCRETE COIN BIASES FROM 0 TO 1 in intervals of 0.1\n",
    "    probEvidenceForBias = probEvidenceForEachBiasVals[int(bias * 10)]\n",
    "    \n",
    "    # Finally, find the probability for that the bias is what it is, given the evidence\n",
    "    bayesPBias = (biasPrior * probEvidenceForBias)/pEvidence\n",
    "    \n",
    "    \n",
    "    return biasPrior, bayesPBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bayesFull calculates the posterior probabilities\n",
    "# of a set of hypotheses. This allows us to compare the prior with the posterior\n",
    "# distribution for all hypotheses\n",
    "# WORKS ONLY FOR DISCRETE SETS OF HYPO VALUES\n",
    "\n",
    "def bayesFull(hyposAndPriorProbs, numTosses, numEvents, slack = 0):\n",
    "    # hypos is the set of biases, e.g., [0, 0.1, ..., 0.9, 1.0] for the possible discrete biases of a coin\n",
    "    # priorProbs is the prior probability of each of the hypos\n",
    "    \n",
    "    # We get hyposAndPriorProbs as the output of a function such as discreteRandomDist(np.arange(0,1.1,0.1))\n",
    "    # The evidence is in the form of the number of heads observed (numEvents) \n",
    "    # when the coin is tosses N times (numTosses).\n",
    "    \n",
    "    # WORKS ONLY FOR DISCRETE SETS OF HYPO VALUES\n",
    "    \n",
    "    # Split hyposAndPriorProbs into hypos and priorProbs\n",
    "    hypos = [hyposAndPriorProb[0] for hyposAndPriorProb in hyposAndPriorProbs]\n",
    "    priorProbs = [hyposAndPriorProb[1] for hyposAndPriorProb in hyposAndPriorProbs]\n",
    "    \n",
    "    # calculate the probability of the evidence for each possible hypo\n",
    "    probEvidenceForEachHypo = [probCoinTossOutcome(hypo,numTosses,numEvents, slack) for hypo in hypos]\n",
    "    # just get the values and normalize in case slack > 0\n",
    "    probEvidenceForEachHypoVals = normalize([probEvidence[4] for probEvidence in probEvidenceForEachHypo])\n",
    "    \n",
    "    # Probability of the evidence per se - i.e., the Bayesian normalization factor\n",
    "    pEvidencePerSe = np.sum(np.multiply(priorProbs, probEvidenceForEachHypoVals))\n",
    "    \n",
    "    # Posterior distribution without Bayesian normalization\n",
    "    postDistRaw = list(np.multiply(priorProbs, probEvidenceForEachHypoVals))\n",
    "    \n",
    "    # Bayesian normalized posterior distribution -- this is usually the one we want\n",
    "    postDist = list(postDistRaw/pEvidencePerSe)\n",
    "    \n",
    "    return priorProbs, postDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3*x**2 + 4*y"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Symbolic partial differentiation -- examples\n",
    "from sympy import symbols, diff\n",
    "x, y, z = symbols('x y z', real=True)\n",
    "f = 4*x*y + x**3 + z**8*y\n",
    "diff(f, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1**2.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0, theta1, theta2, theta3, theta4, x0, x1 = symbols('theta0, theta1, theta2, theta3, theta4, x0, x1', real=True)\n",
    "g = theta0*x0 + theta1*x1 + theta2*x1**2 + theta3*x1**3 + theta4*x1**(2.5)\n",
    "diff(g, theta4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a data set and split it into training, cross-validation, and test data sets\n",
    "def splitDataSet(data, trainRatio, valRatio):\n",
    "    # Randomly shuffle the data -- \n",
    "    # Split up into train (trainRatio of all data), cross validate(valRatio), and test data sets\n",
    "    # NOTE - there's also a sklearn function train_test_split to do a similar thing but not quite\n",
    "    dataArr = np.array(data)\n",
    "    dataDim = dataArr.shape\n",
    "    #print dataArr[0:4,:]\n",
    "    np.random.shuffle(dataArr)\n",
    "    #print dataArr[0:4,:]\n",
    "\n",
    "    # Find out the number of data rows so they can be split up in the right proportion\n",
    "    num_train_rows = int(dataDim[0] * trainRatio)\n",
    "    num_val_rows = int(dataDim[0] * valRatio)\n",
    "    num_test_rows = dataDim[0] - (num_train_rows + num_val_rows)\n",
    "\n",
    "    # Training Data\n",
    "    X_train = dataArr[0:num_train_rows, 0].reshape((num_train_rows, 1))\n",
    "    y_train = dataArr[0:num_train_rows, 1].reshape((num_train_rows, 1))\n",
    "\n",
    "    # Cross Validation Data\n",
    "    X_val = dataArr[num_train_rows:num_train_rows + num_val_rows, 0].reshape((num_val_rows, 1))\n",
    "    y_val = dataArr[num_train_rows:num_train_rows + num_val_rows, 1].reshape((num_val_rows, 1))\n",
    "\n",
    "    # Test Data\n",
    "    X_test = dataArr[:num_test_rows, 0].reshape((num_test_rows, 1))\n",
    "    y_test = dataArr[:num_test_rows, 1].reshape((num_test_rows, 1))\n",
    "    \n",
    "    return [X_train, y_train, X_val, y_val, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta):\n",
    "    # Cost of being wrong calculated over the entire data set\n",
    "    # Assumes that X has a first column of 1s added to it to simplify the notation\n",
    "    # Therefore: X is an m x n matrix and theta is a n x 1 matrix\n",
    "    \n",
    "    # costPerOutput is an m x 1 matrix where each element is the cost for\n",
    "    # the input and its associated output for a particular value of theta\n",
    "    costPerOutput = np.power(((X * theta) - y),2)\n",
    "    \n",
    "    # totalCost is the cost over the entire dataset\n",
    "    totalCost = np.sum(costPerOutput)\n",
    "    \n",
    "    # The cost of getting it wrong is 1/2m of the totalCost (normalized cost)\n",
    "    cost = totalCost / (2 * len(X))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement Gradient Descent\n",
    "def gradientDescent(X, y, theta, alpha, iters):\n",
    "    # NOTE: X must already have a column of 1s added to it\n",
    "    # X is a m x n matrix\n",
    "    # y is a m x 1 matrix\n",
    "    # Theta is a n x 1 matrix\n",
    "    \n",
    "    # Keep track of everything\n",
    "    sumError = np.zeros(shape=(len(theta),1))\n",
    "    sumErrorNorm = np.zeros(shape=(len(theta),1))\n",
    "    temp = np.matrix(np.zeros(theta.shape))\n",
    "    cost = np.zeros(iters)\n",
    "    \n",
    "    for i in range(iters):\n",
    "        # Calculate the non-normalized values for each theta parameter\n",
    "        error = (X * theta) - y\n",
    "        \n",
    "        for j in range(len(theta)):\n",
    "            # Multiply the error vector by the appropriate column of the X matrix and sum it\n",
    "            sumError[j] = np.sum(np.multiply(error, X[:,j]))\n",
    "            \n",
    "            # Normalize the sumError using alpha and m\n",
    "            sumErrorNorm[j] = np.divide(np.multiply(sumError[j], alpha), len(X))\n",
    "            \n",
    "            temp[j,0] = theta[j,0] - sumErrorNorm[j]\n",
    "        \n",
    "        theta = temp\n",
    "        cost[i] = computeCost(X,y,theta)\n",
    "            \n",
    "    \n",
    "    return theta, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
